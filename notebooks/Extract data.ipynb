{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cf38168-cd58-4793-a7a8-52b6e7511304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47403b6f-8b63-44b9-b780-17350b9e2ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/Workspace/Repos/ziaarzoo21@gmail.com/spark-etl/config/config.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {cfg['catalog_name']}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {cfg['catalog_name']}.{cfg['schema_name']}\")\n",
    "\n",
    "from src.extract.save_raw import run as extract_run\n",
    "table_written = extract_run(cfg, spark)\n",
    "\n",
    "df = spark.table(table_written)\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a652513f-6fc0-4530-9c55-94798759d0ab",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"location\":803,\"id\":341},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760958786725}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE DETAIL main.weather_etl.raw_weather\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "545df9bb-ccc4-4cea-93ed-1d98cb324664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loc = spark.sql(\"DESCRIBE DETAIL main.weather_etl.raw_weather\").select(\"location\").collect()[0][0]\n",
    "dbutils.fs.ls(loc)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Extract data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
